{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning: Project Part 1**\n",
    "\n",
    "---\n",
    "\n",
    "**Author: Damien Farrell**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "from transformers import pipeline as hf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "load_dotenv()\n",
    "secret_key = os.environ.get(\"../HF_API_KEY\")\n",
    "\n",
    "# Audio Files\n",
    "audio = \"./audio/TrumpHarrisDebate.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Part 1: Interview/Debate Audio Analysis**\n",
    "\n",
    "> 1. **Performs Speaker Diarisation Analysis**  \n",
    ">    - Uses pre-built models to identify who spoke and when.  \n",
    ">    - Outputs time segments for each speaker and calculates total speaking time.\n",
    "> <br><br>\n",
    "> 2. **Performs Speech to Text Analysis**  \n",
    ">    - Transcribes the audio for each speaker.  \n",
    ">    - Combines speaker labels with the transcript (e.g., “[Speaker 1] …”).  \n",
    ">    - Allows for further analysis, such as word counts or word frequency per speaker.\n",
    "> <br><br>\n",
    "> 3. **Leverages a Large Language Model**  \n",
    ">    - Once the transcript is annotated, the notebook can query a large language model for sentiment or ideological analysis.  \n",
    ">    - Could identify speaker names or approximate political leanings based on transcript content.\n",
    "> <br><br>\n",
    "> 4. **Testing & Evaluation**  \n",
    ">    - An audio file of the “Harris vs. Trump 2024 US Presidential Debate” will be provided for initial testing.  \n",
    ">    - A more complex file (with additional speakers or speakers of similar gender) should be used for further evaluation.  \n",
    ">    - The performance of each component should be documented and assessed.\n",
    "> <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Performs Speaker Diarisation Analysis** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7862a521b82e4a478d0c7a3ebe5a3255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/damien/Documents/ATU/machine-learning/.venv/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling\n",
       ".py:104: UserWarning: std(): degrees of freedom is &lt;= 0. Correction should be strictly less than the reduction \n",
       "factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/damien/Documents/ATU/machine-learning/.venv/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling\n",
       ".py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction \n",
       "factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the pipeline on an audio file\n",
    "with ProgressHook() as hook:\n",
    "    diarization = pipeline(audio, hook=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyannote.core.annotation.Annotation'>\n"
     ]
    }
   ],
   "source": [
    "print(type(diarization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPEAKER_00', 'SPEAKER_01', 'SPEAKER_02']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarization.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SPEAKER_02', 87.19312499999997),\n",
       " ('SPEAKER_01', 81.84375),\n",
       " ('SPEAKER_00', 25.835624999999993)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarization.chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### **References**\n",
    "\n",
    "1. https://huggingface.co/pyannote/segmentation\n",
    "2. http://pyannote.github.io/pyannote-core/reference.html#annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
